基于多模态数据的三维情感模型参数映射方案
​1. X轴（效价）：生理信号与表情的融合
​核心数据：​表情效价 + ​心跳间隔（IBI）​
​表情效价：通过面部表情识别模型（如face-api.js）直接输出效价得分，正表情（如微笑、喜悦）对应+100，负表情（如皱眉、愤怒）对应-100。
​心跳间隔（IBI）​：通过心率变异性（HRV）的RMSSD值​（相邻心跳间隔的均方根差）反映自主神经系统状态。
​高HRV​（RMSSD>50ms）→ ​正向效价​（放松/愉悦）
​低HRV​（RMSSD<20ms）→ ​负向效价​（压力/焦虑）
​融合公式：
X = 0.7×表情效价 + 0.3×(HRV_norm×200-100)
（归一化后HRV范围映射到-100~+100）
​2. Y轴（唤醒度）：动态生理特征主导
​核心数据：​心率（BPM）​ + ​PPG信号动态特征
​BPM基线唤醒：静息心率（60~80 BPM）映射到Y轴中段（50），剧烈波动（如>100 BPM）映射到高唤醒区（80~100）。
​PPG信号上升斜率：通过微分计算脉搏波形的上升速度，斜率越大（如>1.2V/s）表示瞬时唤醒度越高（如兴奋、紧张）。
​融合公式：
Y = 0.6×BPM_norm + 0.4×PPG_斜率_norm
（截断至0~100，避免超限）
​3. Z轴（情感类型）：表情分类为主，生理信号验证
​表情主导分类：
使用深度学习模型（如CNN）直接输出情感概率分布（喜悦/悲伤/愤怒等）。
​生理信号验证：
​喜悦：BPM稳定偏高（90~110）+ PPG波形对称性高
​愤怒：BPM骤升 + PPG波形出现双峰特征
​悲伤：BPM偏低（<60） + PPG波形平缓
​控制逻辑：当表情置信度<80%时，结合PPG周期模式修正分类结果。
